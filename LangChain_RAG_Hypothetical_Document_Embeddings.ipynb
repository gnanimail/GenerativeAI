{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcMxUNWSzY2a3+6XW9kf9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnanimail/GenerativeAI/blob/main/LangChain_RAG_Hypothetical_Document_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHdXgHbpqPk0",
        "outputId": "740c3c4b-77c2-4c15-df9e-be0a22eb3947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.6/508.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain huggingface_hub openai chromadb tiktoken faiss-cpu\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install -U FlagEmbedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a folder called blogs post and upload the documents\n"
      ],
      "metadata": {
        "id": "qzTSAClZrafc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p blog_posts"
      ],
      "metadata": {
        "id": "EigdcLtTrRvZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/blog_posts/langchain_blog_posts.zip -d blog_posts"
      ],
      "metadata": {
        "id": "rpHRx4EKrR0n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hypothetical Document Embeddings (HyDE)\n",
        "\n",
        "HyDE creates a \"Hypothetical\" answer with the LLM and then embeds that for search\n",
        "\n",
        "HyDE = Base Embedding model + LLM Chain (with prompts)\n"
      ],
      "metadata": {
        "id": "ayQYPUVQr0Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "import langchain"
      ],
      "metadata": {
        "id": "dK880fHirR4D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BGE Embeddings"
      ],
      "metadata": {
        "id": "0x9_x3mHsE-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en-v1.5\"\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "YzW21C2XrR7O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "BHDHtrKpsSdy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the LLM\n",
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "vjhxjCOqrR-p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load with `web_search` prompt\n",
        "embeddings = HypotheticalDocumentEmbedder.from_llm(llm,\n",
        "                                                   bge_embeddings,\n",
        "                                                   prompt_key=\"web_search\"\n",
        "                                                   )"
      ],
      "metadata": {
        "id": "POTstYAprSCO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.llm_chain.prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHVYd4x7rSFD",
        "outputId": "ff7307ef-98fe-4602-b8fd-eeb7b240f30c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['QUESTION'], template='Please write a passage to answer the question \\nQuestion: {QUESTION}\\nPassage:')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = True"
      ],
      "metadata": {
        "id": "2hfibKFLrSIF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can use it as any embedding class!\n",
        "result = embeddings.embed_query(\"What items does McDonalds make?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlNYd8gwrSLQ",
        "outputId": "cbe62f55-cde6-4302-9e79-549d8be565fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Please write a passage to answer the question \\nQuestion: What items does McDonalds make?\\nPassage:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:OpenAI] [1.73s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" McDonald's is a fast-food chain that is known for its iconic golden arches and signature menu items. Some of the most popular items that McDonald's makes include their famous Big Mac burger, crispy French fries, and savory Chicken McNuggets. They also offer a variety of burgers such as the Quarter Pounder and the Double Cheeseburger, as well as breakfast items like the Egg McMuffin and hotcakes. McDonald's also offers a range of beverages including soft drinks, iced coffee, and milkshakes. In addition to their classic menu items, McDonald's also offers seasonal and limited-time offerings, such as the McRib sandwich and the Shamrock Shake. No matter what your taste buds are craving, McDonald's has a wide selection of items that are sure to satisfy your hunger.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"total_tokens\": 180,\n",
            "      \"completion_tokens\": 159,\n",
            "      \"prompt_tokens\": 21\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP-RX6-0rSOT",
        "outputId": "b4ebdcca-1dbb-4dc6-ece1-8ecaff45b584"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.035439178347587585,\n",
              " -0.025407783687114716,\n",
              " 0.03329573571681976,\n",
              " -0.034941066056489944,\n",
              " 0.0757293626666069,\n",
              " 0.04722718149423599,\n",
              " 0.07754840701818466,\n",
              " -0.036017436534166336,\n",
              " 0.015836050733923912,\n",
              " -0.027463000267744064,\n",
              " -0.002132850233465433,\n",
              " -0.03373127803206444,\n",
              " -0.01838061772286892,\n",
              " -0.01632639579474926,\n",
              " 0.058415040373802185,\n",
              " -0.011163322255015373,\n",
              " 0.004437052179127932,\n",
              " -0.09779062867164612,\n",
              " -0.050163090229034424,\n",
              " -0.049110379070043564,\n",
              " 0.04895024001598358,\n",
              " -0.010361721739172935,\n",
              " -0.07581503689289093,\n",
              " 0.006144003942608833,\n",
              " 0.061498839408159256,\n",
              " -0.03676167130470276,\n",
              " 0.06026726961135864,\n",
              " 0.0031885746866464615,\n",
              " -0.03813385218381882,\n",
              " -0.10889343917369843,\n",
              " 0.017044611275196075,\n",
              " -0.060427989810705185,\n",
              " 0.04345579072833061,\n",
              " -0.10992053896188736,\n",
              " -0.03572080284357071,\n",
              " -0.004481951706111431,\n",
              " 0.030588287860155106,\n",
              " -0.039635755121707916,\n",
              " 0.006911880802363157,\n",
              " -0.021607067435979843,\n",
              " 0.05596912279725075,\n",
              " 0.00495034409686923,\n",
              " 0.045476365834474564,\n",
              " -0.03652847558259964,\n",
              " 0.06999487429857254,\n",
              " 0.017831837758421898,\n",
              " -0.026931583881378174,\n",
              " -0.049522239714860916,\n",
              " 0.10815306007862091,\n",
              " -0.020505815744400024,\n",
              " 0.03085089847445488,\n",
              " -0.02781090699136257,\n",
              " -0.016760816797614098,\n",
              " 0.008524280972778797,\n",
              " 0.022964876145124435,\n",
              " 0.08672694861888885,\n",
              " -0.0036867959424853325,\n",
              " -0.08395203948020935,\n",
              " 0.061409834772348404,\n",
              " -0.01643316075205803,\n",
              " 0.0423969104886055,\n",
              " 0.011953257955610752,\n",
              " -0.0703570768237114,\n",
              " 0.09880216419696808,\n",
              " -0.023685848340392113,\n",
              " 0.01661210134625435,\n",
              " 0.018699929118156433,\n",
              " 0.04523702710866928,\n",
              " -0.05165151506662369,\n",
              " -0.0019580256193876266,\n",
              " -0.014093036763370037,\n",
              " -0.03103482350707054,\n",
              " 0.00010272398503730074,\n",
              " 0.07302846014499664,\n",
              " -0.0374908372759819,\n",
              " -0.07086803764104843,\n",
              " 0.0499892383813858,\n",
              " -0.04874042049050331,\n",
              " -0.05613543093204498,\n",
              " 0.09739922732114792,\n",
              " 0.028076982125639915,\n",
              " -0.05986994132399559,\n",
              " 0.019419163465499878,\n",
              " -0.019606564193964005,\n",
              " -0.05740439146757126,\n",
              " -0.03378799185156822,\n",
              " -0.03127612918615341,\n",
              " 0.013160958886146545,\n",
              " 0.048616621643304825,\n",
              " 0.011783318594098091,\n",
              " -0.038618303835392,\n",
              " -0.028540413826704025,\n",
              " 0.006727623753249645,\n",
              " -0.018614942207932472,\n",
              " -0.015950685366988182,\n",
              " -0.0113631347194314,\n",
              " -0.011523649096488953,\n",
              " -0.05758309364318848,\n",
              " 0.04034215584397316,\n",
              " 0.38917866349220276,\n",
              " 0.009816882200539112,\n",
              " 0.11030299961566925,\n",
              " 0.04489919915795326,\n",
              " -0.036492351442575455,\n",
              " 0.05849642679095268,\n",
              " -0.03284129127860069,\n",
              " 0.06955987960100174,\n",
              " 0.0921136885881424,\n",
              " 0.0378970205783844,\n",
              " 0.016914254054427147,\n",
              " 0.010986650362610817,\n",
              " -0.004439034499228001,\n",
              " 0.05470544844865799,\n",
              " -0.02679266966879368,\n",
              " 0.013803219422698021,\n",
              " -0.06221453845500946,\n",
              " 0.016255363821983337,\n",
              " 0.0260003712028265,\n",
              " -0.012598968110978603,\n",
              " 0.0033859964460134506,\n",
              " -0.0231726486235857,\n",
              " 0.06506247073411942,\n",
              " 0.04298713803291321,\n",
              " 0.027515416964888573,\n",
              " -0.08471346646547318,\n",
              " -0.015360020101070404,\n",
              " -0.002876450540497899,\n",
              " 0.0478338859975338,\n",
              " 0.038078777492046356,\n",
              " 0.0009149565594270825,\n",
              " -0.014789101667702198,\n",
              " -0.03206956386566162,\n",
              " 0.05937376245856285,\n",
              " -0.007097236346453428,\n",
              " 0.012421499006450176,\n",
              " 0.03137347474694252,\n",
              " -0.006419333163648844,\n",
              " -0.046351369470357895,\n",
              " 0.011604996398091316,\n",
              " 0.03064696304500103,\n",
              " -0.029103901237249374,\n",
              " -0.015294050797820091,\n",
              " 0.033126335591077805,\n",
              " -0.12159421294927597,\n",
              " 0.002592752454802394,\n",
              " 0.05893133208155632,\n",
              " -0.018436696380376816,\n",
              " 0.04001021385192871,\n",
              " -0.04333756864070892,\n",
              " 0.06191965192556381,\n",
              " 0.05768148973584175,\n",
              " -0.006342777516692877,\n",
              " 0.026982663199305534,\n",
              " -0.02498072013258934,\n",
              " -0.029082078486680984,\n",
              " 0.021030845120549202,\n",
              " 0.0699395164847374,\n",
              " -0.03723975270986557,\n",
              " 0.034958288073539734,\n",
              " 0.008516129106283188,\n",
              " -0.06622915714979172,\n",
              " -0.0339474081993103,\n",
              " 0.01882142946124077,\n",
              " -0.026602787896990776,\n",
              " 0.0020480884704738855,\n",
              " -0.16156457364559174,\n",
              " -0.04337337613105774,\n",
              " -0.005620339885354042,\n",
              " -0.026916682720184326,\n",
              " -0.04178191348910332,\n",
              " 0.013883969746530056,\n",
              " 0.06016544997692108,\n",
              " -0.04610051214694977,\n",
              " 0.03124796412885189,\n",
              " 0.1049644947052002,\n",
              " 0.05129129812121391,\n",
              " -0.042719766497612,\n",
              " 0.015642544254660606,\n",
              " -0.014385531656444073,\n",
              " -0.010108821094036102,\n",
              " 0.02458387427031994,\n",
              " -0.005988738499581814,\n",
              " -0.05374406650662422,\n",
              " 0.004952596500515938,\n",
              " 0.04318526014685631,\n",
              " -0.06281720101833344,\n",
              " 0.011504815891385078,\n",
              " 0.013499370776116848,\n",
              " 0.03922228515148163,\n",
              " 0.039353273808956146,\n",
              " 0.02954494021832943,\n",
              " 0.0015051179798319936,\n",
              " -0.03593021631240845,\n",
              " -0.024120816960930824,\n",
              " -0.05401656776666641,\n",
              " -0.01304185763001442,\n",
              " 0.00751472357660532,\n",
              " 0.03988036885857582,\n",
              " 0.08202309906482697,\n",
              " -0.0331977903842926,\n",
              " -0.06041178107261658,\n",
              " -0.020131124183535576,\n",
              " -0.028604935854673386,\n",
              " -0.05048859491944313,\n",
              " -0.011067481711506844,\n",
              " 0.03977400064468384,\n",
              " -0.04251175746321678,\n",
              " -0.022009752690792084,\n",
              " -0.018290460109710693,\n",
              " -0.07867788523435593,\n",
              " -0.009083465673029423,\n",
              " 0.028118208050727844,\n",
              " -0.02567070908844471,\n",
              " 0.02790193259716034,\n",
              " -0.007521302904933691,\n",
              " -0.08126858621835709,\n",
              " 0.03141443058848381,\n",
              " 0.03099961206316948,\n",
              " -0.014264876022934914,\n",
              " -0.05393903702497482,\n",
              " 0.0789155513048172,\n",
              " -0.027987554669380188,\n",
              " -0.06254301220178604,\n",
              " -0.2572653293609619,\n",
              " 0.015401758253574371,\n",
              " -0.013247639872133732,\n",
              " 0.008235931396484375,\n",
              " 0.025252817198634148,\n",
              " -0.009485875256359577,\n",
              " 0.0056887161917984486,\n",
              " -0.010701361112296581,\n",
              " -0.017803573980927467,\n",
              " 0.03495491296052933,\n",
              " 0.04238492622971535,\n",
              " 0.020353367552161217,\n",
              " -0.01633894257247448,\n",
              " -0.020197903737425804,\n",
              " -0.0006446681800298393,\n",
              " 0.05936530977487564,\n",
              " -0.003866342129185796,\n",
              " -0.07413344085216522,\n",
              " 0.058640558272600174,\n",
              " -0.0021332718897610903,\n",
              " 0.013483542948961258,\n",
              " 0.03398290276527405,\n",
              " -0.04839973524212837,\n",
              " 0.053722627460956573,\n",
              " 0.009611878544092178,\n",
              " 0.047408152371644974,\n",
              " 0.10159718245267868,\n",
              " 0.080284982919693,\n",
              " 0.022551272064447403,\n",
              " -0.05200359970331192,\n",
              " -0.01715223677456379,\n",
              " 0.06790649890899658,\n",
              " 0.02209320478141308,\n",
              " -0.02777097187936306,\n",
              " 0.03585033491253853,\n",
              " -0.02479524537920952,\n",
              " 0.01772516779601574,\n",
              " -0.043553490191698074,\n",
              " -0.06441158056259155,\n",
              " 0.0010263490257784724,\n",
              " -0.11763501167297363,\n",
              " 0.01846836693584919,\n",
              " -0.0026183186564594507,\n",
              " -0.028099939227104187,\n",
              " -0.0041047027334570885,\n",
              " -0.031463008373975754,\n",
              " 0.026170598343014717,\n",
              " 0.010931149125099182,\n",
              " -0.033510420471429825,\n",
              " 0.003574850969016552,\n",
              " -0.025518862530589104,\n",
              " -0.0195987019687891,\n",
              " 0.031913112848997116,\n",
              " -0.013464132323861122,\n",
              " 0.0031811136286705732,\n",
              " 0.027528248727321625,\n",
              " -0.02771817333996296,\n",
              " -0.05784936994314194,\n",
              " -0.008520551957190037,\n",
              " -0.0025324434973299503,\n",
              " -0.01281382143497467,\n",
              " -0.07696691900491714,\n",
              " -0.0424039289355278,\n",
              " 0.005702135618776083,\n",
              " 0.02893177419900894,\n",
              " -0.004413139540702105,\n",
              " -0.02132413722574711,\n",
              " 0.026663055643439293,\n",
              " -0.08004319667816162,\n",
              " 0.02754472754895687,\n",
              " -0.07247640192508698,\n",
              " 0.05841178447008133,\n",
              " -0.012670841068029404,\n",
              " 0.07315715402364731,\n",
              " 0.06461185961961746,\n",
              " -0.014795780181884766,\n",
              " -0.008328755386173725,\n",
              " -0.03337117284536362,\n",
              " -0.023766865953803062,\n",
              " -0.023436909541487694,\n",
              " 0.03532179817557335,\n",
              " 0.04196103289723396,\n",
              " -0.06045681610703468,\n",
              " 0.029006849974393845,\n",
              " 0.020178895443677902,\n",
              " -0.003954378888010979,\n",
              " 0.0007618109812028706,\n",
              " 0.023728225380182266,\n",
              " 0.0081215500831604,\n",
              " 0.018747728317975998,\n",
              " -0.019314216449856758,\n",
              " -0.04294808208942413,\n",
              " 0.01582692563533783,\n",
              " -0.042868923395872116,\n",
              " 0.024728240445256233,\n",
              " 0.014473586343228817,\n",
              " -0.21079622209072113,\n",
              " 0.046665824949741364,\n",
              " 0.0032905268017202616,\n",
              " 0.016432395204901695,\n",
              " 0.05741667374968529,\n",
              " -0.026867609471082687,\n",
              " -0.0783347338438034,\n",
              " -0.02570963464677334,\n",
              " -0.03293395787477493,\n",
              " 0.018596351146697998,\n",
              " 0.07980701327323914,\n",
              " -0.018723802641034126,\n",
              " 0.060533925890922546,\n",
              " -0.018062114715576172,\n",
              " -0.002038901438936591,\n",
              " 0.00821305625140667,\n",
              " 0.032111041247844696,\n",
              " 0.0031951593700796366,\n",
              " 0.07349743694067001,\n",
              " 0.004441727418452501,\n",
              " 0.02974240481853485,\n",
              " -0.019618986174464226,\n",
              " 0.12848976254463196,\n",
              " 0.058808669447898865,\n",
              " -0.01593383587896824,\n",
              " -0.0014427679125219584,\n",
              " -0.008885752409696579,\n",
              " 0.039757631719112396,\n",
              " -0.0560690313577652,\n",
              " 0.04647389426827431,\n",
              " 0.11477234214544296,\n",
              " -0.04932397976517677,\n",
              " 0.08709365874528885,\n",
              " -0.02298980951309204,\n",
              " -0.019439740106463432,\n",
              " 0.03645949065685272,\n",
              " -0.01864146627485752,\n",
              " 0.018586892634630203,\n",
              " -0.02162947691977024,\n",
              " 0.008935320191085339,\n",
              " -0.050025008618831635,\n",
              " 0.004033791832625866,\n",
              " -0.07805934548377991,\n",
              " -0.05225411057472229,\n",
              " 0.05419088155031204,\n",
              " -0.03892993554472923,\n",
              " -0.0011306705418974161,\n",
              " -0.059601474553346634,\n",
              " -0.012064779177308083,\n",
              " -0.021994994953274727,\n",
              " 0.007539856247603893,\n",
              " -0.018521083518862724,\n",
              " 0.03403383493423462,\n",
              " 0.016084156930446625,\n",
              " 0.04160843417048454,\n",
              " -0.042473744601011276,\n",
              " -0.049934420734643936,\n",
              " 0.04532886669039726,\n",
              " -0.03832599148154259,\n",
              " 0.021391764283180237,\n",
              " -0.001103857415728271,\n",
              " 0.08036144077777863,\n",
              " -0.01864319108426571,\n",
              " 0.11537358909845352,\n",
              " -0.0028745573945343494]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multiple generations\n",
        "Generate multiple hypothetical answers\n",
        "\n",
        "We can also generate multiple documents and then combine the embeddings for those. By default, we combine those by taking the average. We can do this by changing the LLM we use to generate documents to return multiple things.\n",
        "\n"
      ],
      "metadata": {
        "id": "a8Ptiq-Ds-OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_llm = OpenAI(n=4, best_of=4)"
      ],
      "metadata": {
        "id": "K0gAtE-jrSQ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder.from_llm(multi_llm, bge_embeddings, \"web_search\")"
      ],
      "metadata": {
        "id": "YRTLw-XOrSVd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_result = embeddings.embed_query(\"What is McDonalds best selling item?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHnnhx8krSX9",
        "outputId": "6f663548-9989-4aa6-c587-19f76484e25b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Please write a passage to answer the question \\nQuestion: What is McDonalds best selling item?\\nPassage:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:OpenAI] [3.35s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" McDonald's, one of the largest fast food chains in the world, offers a wide variety of menu items ranging from burgers and fries to salads and desserts. With so many options to choose from, it may be difficult to pinpoint their best selling item. However, through years of sales data and customer preferences, it is safe to say that McDonald's best selling item is their classic Big Mac burger. This iconic burger, first introduced in 1968, consists of two all-beef patties, special sauce, lettuce, cheese, pickles, and onions, all served on a sesame seed bun. The Big Mac has remained a fan favorite for over 50 years, with its unique combination of flavors and the famous jingle \\\"Two all-beef patties, special sauce, lettuce, cheese, pickles, onions on a sesame seed bun\\\" becoming a part of popular culture. In addition to its popularity among customers, the Big Mac also holds a special place in McDonald's history, making it a staple item on their menu and their best selling item. However, with the ever-changing tastes and preferences of consumers, only time will tell if the Big Mac will continue to hold its title as McDonald's best selling item.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \" McDonald's is one of the most popular fast food chains in the world, known for its signature golden arches and iconic menu items. While the restaurant offers a variety of options ranging from burgers to salads, there is one item that stands out as the best-selling item on the menu. This item is none other than the classic McDonald's French fries. These crispy, golden potato sticks are a staple for many customers and have been a top seller for decades. The fries are made from high-quality potatoes and are cooked to perfection, creating a deliciously addictive taste that keeps customers coming back for more. Whether paired with a burger or enjoyed on their own, McDonald's French fries are undeniably the best-selling item and a fan favorite around the world. \",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \" McDonald's is a global fast food chain that is known for its wide array of menu items. From burgers and fries to chicken nuggets and milkshakes, McDonald's has something for everyone. However, there is one item that stands out above the rest as the best selling item on their menu. Can you guess what it is? That's right, it's the Big Mac. This iconic burger, with its two all-beef patties, special sauce, lettuce, cheese, pickles, onions, all on a sesame seed bun, has been a fan favorite since its introduction in 1967. In fact, McDonald's sells over 900 million Big Macs every year worldwide. This beloved burger has become a staple in the fast food industry and continues to be the go-to item for many McDonald's customers. So, next time you visit a McDonald's, don't forget to try their best selling item, the Big Mac.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \" McDonald's is a globally renowned fast-food chain, known for its wide range of delicious and affordable menu items. From burgers and fries to milkshakes and salads, McDonald's has something for everyone. However, one item stands out as the best-selling and most popular among customers. The iconic Big Mac sandwich has been a staple on the McDonald's menu since its introduction in 1967. Made with two all-beef patties, special sauce, lettuce, cheese, pickles, and onions on a sesame seed bun, the Big Mac has become a fan-favorite worldwide. It is estimated that McDonald's sells over 550 million Big Macs every year, making it the best-selling item on their menu. Its unique taste, consistency, and affordability have made it a go-to choice for many McDonald's customers, solidifying its spot as their top-selling item. Whether you're craving a quick meal on the go or simply looking for a delicious burger fix, the Big Mac is undoubtedly McDonald's best-selling item.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"total_tokens\": 811,\n",
            "      \"completion_tokens\": 789,\n",
            "      \"prompt_tokens\": 22\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDrRmT5nrSaZ",
        "outputId": "9f34d9ba-c3cf-4c86-8683-3f67c58ee5e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.026110883336514235,\n",
              " -0.030623276950791478,\n",
              " 0.006427774176700041,\n",
              " -0.028816506965085864,\n",
              " 0.08462274074554443,\n",
              " 0.04110136069357395,\n",
              " 0.05834059137851,\n",
              " -0.01827018428593874,\n",
              " 0.02046056790277362,\n",
              " 0.0008152211812557653,\n",
              " 0.006893265526741743,\n",
              " -0.016049637109972537,\n",
              " 0.01408608490601182,\n",
              " -0.0399749418720603,\n",
              " 0.023757285438477993,\n",
              " 0.007500176900066435,\n",
              " 0.028322458470938727,\n",
              " -0.09294118452817202,\n",
              " -0.051448533311486244,\n",
              " -0.06292201578617096,\n",
              " 0.06941710319370031,\n",
              " -0.007844566542189568,\n",
              " -0.068781946785748,\n",
              " 0.018221843987703323,\n",
              " 0.06951396819204092,\n",
              " -0.035583244636654854,\n",
              " 0.029605895280838013,\n",
              " 0.007798735547112301,\n",
              " -0.04166520875878632,\n",
              " -0.15850812941789627,\n",
              " 0.009885355830192566,\n",
              " -0.06376910395920277,\n",
              " 0.04545060032978654,\n",
              " -0.04565062187612057,\n",
              " -0.03954887483268976,\n",
              " -0.001098408829420805,\n",
              " 0.024154019076377153,\n",
              " -0.05392732843756676,\n",
              " 0.023182417498901486,\n",
              " -0.002422026765998453,\n",
              " 0.07131204660981894,\n",
              " 0.007390273734927177,\n",
              " 0.03394834324717522,\n",
              " -0.03704268718138337,\n",
              " 0.061171384528279305,\n",
              " 0.03404735785443336,\n",
              " -0.014784694008994848,\n",
              " -0.029023003298789263,\n",
              " 0.10278324969112873,\n",
              " 0.004039587220177054,\n",
              " 0.015103577810805291,\n",
              " -0.008132941089570522,\n",
              " -0.04260303406044841,\n",
              " -0.007404514122754335,\n",
              " 0.028890144545584917,\n",
              " 0.09378914348781109,\n",
              " -0.0028794004465453327,\n",
              " -0.04634169535711408,\n",
              " 0.0230310563929379,\n",
              " 0.005492437048815191,\n",
              " 0.01712658314500004,\n",
              " 0.009657894999691052,\n",
              " -0.10738329403102398,\n",
              " 0.10019792057573795,\n",
              " -0.017848032992333174,\n",
              " 0.01381467969622463,\n",
              " 0.04258586000651121,\n",
              " 0.027939445339143276,\n",
              " -0.09347546845674515,\n",
              " -0.009529719478450716,\n",
              " 0.014328038785606623,\n",
              " 0.016045786440372467,\n",
              " 0.015072121284902096,\n",
              " 0.07599727530032396,\n",
              " -0.0344905024394393,\n",
              " -0.05750377755612135,\n",
              " 0.0404614619910717,\n",
              " -0.025673304684460163,\n",
              " -0.05143231339752674,\n",
              " 0.08920181542634964,\n",
              " 0.0314300530590117,\n",
              " -0.011094664863776416,\n",
              " -0.014873636129777879,\n",
              " -0.06374804675579071,\n",
              " -0.06523691397160292,\n",
              " -0.04858774319291115,\n",
              " -0.03535096498671919,\n",
              " 0.024758974672295153,\n",
              " 0.06082386989146471,\n",
              " -0.011307142209261656,\n",
              " 0.005167899245861918,\n",
              " -0.02854257309809327,\n",
              " 0.02193367714062333,\n",
              " -0.0364506165497005,\n",
              " -0.04754653573036194,\n",
              " -0.003227440669434145,\n",
              " -0.037003323435783386,\n",
              " -0.03168313670903444,\n",
              " 0.04132398730143905,\n",
              " 0.3865257278084755,\n",
              " -0.01824759761802852,\n",
              " 0.0666198804974556,\n",
              " 0.016923910472542048,\n",
              " -0.059954095631837845,\n",
              " 0.033518248004838824,\n",
              " 0.0026474795304238796,\n",
              " 0.0484483246691525,\n",
              " 0.07346540503203869,\n",
              " 0.029115056386217475,\n",
              " 0.015916911652311683,\n",
              " 0.001957317173946649,\n",
              " 0.03804778610356152,\n",
              " 0.025106030283495784,\n",
              " -0.017839026870206,\n",
              " 0.017216050531715155,\n",
              " -0.09136074408888817,\n",
              " 0.042003047186881304,\n",
              " 0.022137080319225788,\n",
              " 0.010814243811182678,\n",
              " 0.0042281553614884615,\n",
              " -0.02492483053356409,\n",
              " 0.08099558763206005,\n",
              " 0.016116876126034185,\n",
              " 0.010800489078974351,\n",
              " -0.0632914979942143,\n",
              " -0.02509530133102089,\n",
              " -0.012106594513170421,\n",
              " 0.04884221497923136,\n",
              " 0.02740628132596612,\n",
              " -0.00274278677534312,\n",
              " -0.0076349134324118495,\n",
              " -0.06737261451780796,\n",
              " 0.016881047282367945,\n",
              " -0.026751121738925576,\n",
              " 0.04005666743614711,\n",
              " 0.027738596661947668,\n",
              " 0.01508297618420329,\n",
              " 0.028662913711741567,\n",
              " 0.005675440421327949,\n",
              " -0.02986119221895933,\n",
              " 0.0016374799888581038,\n",
              " -0.04012212483212352,\n",
              " 0.024648416903801262,\n",
              " -0.07499226089566946,\n",
              " 0.024117159249726683,\n",
              " 0.05636490602046251,\n",
              " -0.011803658562712371,\n",
              " 0.028470356366597116,\n",
              " -0.048814243637025356,\n",
              " 0.0770408920943737,\n",
              " 0.03875205898657441,\n",
              " -0.003595218586269766,\n",
              " 0.0016026526864152402,\n",
              " -0.008237077126977965,\n",
              " 0.02820768707897514,\n",
              " 0.007378677721135318,\n",
              " 0.05046722572296858,\n",
              " 0.010599526693113148,\n",
              " 0.003206474269973114,\n",
              " -0.013792973826639354,\n",
              " -0.08934680931270123,\n",
              " -0.015120760072022676,\n",
              " 0.00012092781253159046,\n",
              " -0.039477233309298754,\n",
              " 0.007524250657297671,\n",
              " -0.1435321532189846,\n",
              " -0.030160590074956417,\n",
              " 0.014473640359938145,\n",
              " -0.014573694672435522,\n",
              " -0.01973607880063355,\n",
              " 0.0032481520902365446,\n",
              " 0.037042296375148,\n",
              " -0.06837333831936121,\n",
              " 0.035694222897291183,\n",
              " 0.054673497565090656,\n",
              " 0.030015274649485946,\n",
              " -0.05475487420335412,\n",
              " -0.011012710630893707,\n",
              " -0.04541471693664789,\n",
              " -0.006436497322283685,\n",
              " 0.0383554738946259,\n",
              " -0.038922800216823816,\n",
              " -0.03976348042488098,\n",
              " -0.008493559078488033,\n",
              " 0.04057457996532321,\n",
              " -0.047288984060287476,\n",
              " 0.00047107829595915973,\n",
              " 0.017326573841273785,\n",
              " 0.018093743361532688,\n",
              " 0.06994761992245913,\n",
              " 0.042701260186731815,\n",
              " 0.02213671919889748,\n",
              " -0.03897273447364569,\n",
              " -0.006666068802587688,\n",
              " -0.02295937342569232,\n",
              " -0.027001621783711016,\n",
              " -0.04554557194933295,\n",
              " 0.05026554688811302,\n",
              " 0.0992618203163147,\n",
              " -0.016527726576896384,\n",
              " -0.03482943226117641,\n",
              " -0.04257754608988762,\n",
              " -0.06589116156101227,\n",
              " -0.06251830141991377,\n",
              " -0.0279525606893003,\n",
              " 0.0371648920699954,\n",
              " -0.008547825767891482,\n",
              " -0.026364295976236463,\n",
              " -0.029862043680623174,\n",
              " -0.03377545299008489,\n",
              " -0.010408167261630297,\n",
              " 0.02078233240172267,\n",
              " -0.04102768411394209,\n",
              " 0.05682097189128399,\n",
              " -0.045876720920205116,\n",
              " -0.03464080486446619,\n",
              " 0.019319503684528172,\n",
              " 0.0406075194478035,\n",
              " -0.031192984897643328,\n",
              " -0.00766212004236877,\n",
              " 0.06705673225224018,\n",
              " -0.029715032316744328,\n",
              " -0.05035233683884144,\n",
              " -0.2616749554872513,\n",
              " 0.0037771693896502256,\n",
              " -0.02681040856987238,\n",
              " 0.005842421734996606,\n",
              " 0.09448691457509995,\n",
              " -0.035167300957255065,\n",
              " -0.00908315961714834,\n",
              " -0.020402267342433333,\n",
              " -0.006546927150338888,\n",
              " 0.05000283941626549,\n",
              " 0.04305189452134073,\n",
              " -0.0018519391305744648,\n",
              " -0.015980532858520746,\n",
              " -0.0004009758704341948,\n",
              " -0.014810747001320124,\n",
              " 0.052628783509135246,\n",
              " -0.012884201714769006,\n",
              " -0.0707913190126419,\n",
              " 0.03832112159579992,\n",
              " 0.012312996434047818,\n",
              " 0.035449251532554626,\n",
              " 0.009832130104769021,\n",
              " -0.03241733415052295,\n",
              " 0.03661391790956259,\n",
              " 0.013656689843628556,\n",
              " 0.017782265422283672,\n",
              " 0.12076179683208466,\n",
              " 0.05564249213784933,\n",
              " 0.03916352614760399,\n",
              " -0.04242441849783063,\n",
              " -0.016307614918332547,\n",
              " 0.03331741550937295,\n",
              " -0.00964125822247297,\n",
              " 0.01285287455539219,\n",
              " 0.04257631581276655,\n",
              " -0.003957947599701583,\n",
              " -0.013940049801021814,\n",
              " -0.04857083968818188,\n",
              " -0.051463126204907894,\n",
              " 0.007375773100648075,\n",
              " -0.06099667586386204,\n",
              " -0.021173056156840175,\n",
              " 0.00043238780926913023,\n",
              " -0.06774456985294819,\n",
              " 0.0123231231700629,\n",
              " -0.027882987051270902,\n",
              " 0.06385048665106297,\n",
              " 0.02924649929627776,\n",
              " -0.011198011576198041,\n",
              " 0.035802329890429974,\n",
              " -0.02522228891029954,\n",
              " -0.014875652152113616,\n",
              " 0.05090986378490925,\n",
              " 0.014644235779996961,\n",
              " 0.004834662890061736,\n",
              " 0.0017543195135658607,\n",
              " 0.009317018768342678,\n",
              " -0.05217253044247627,\n",
              " 0.005910187028348446,\n",
              " 0.022176461687195115,\n",
              " -0.03924767253920436,\n",
              " -0.01015784777700901,\n",
              " -0.03154603356961161,\n",
              " 0.003714298742124811,\n",
              " 0.015832628938369453,\n",
              " -0.0020294631540309638,\n",
              " 0.025404251646250486,\n",
              " 0.03933576634153724,\n",
              " -0.04724257008638233,\n",
              " -0.0027173087000846863,\n",
              " -0.049644229002296925,\n",
              " 0.049889685586094856,\n",
              " 0.01978762319777161,\n",
              " 0.03468204033561051,\n",
              " 0.07488763146102428,\n",
              " 0.019095915369689465,\n",
              " -0.0011344827362336218,\n",
              " -0.06910202745348215,\n",
              " -0.02223972463980317,\n",
              " -0.024900211254134774,\n",
              " 0.05917617026716471,\n",
              " -0.0008974912343546748,\n",
              " -0.03216611599782482,\n",
              " 0.028993084852118045,\n",
              " 0.044111258699558675,\n",
              " -0.002255239392980002,\n",
              " -0.012292328756302595,\n",
              " 0.031551511492580175,\n",
              " -0.0002653341507539153,\n",
              " 0.011738522560335696,\n",
              " 0.013111993772326969,\n",
              " -0.034550408367067575,\n",
              " -0.02382167731411755,\n",
              " -0.0335198282264173,\n",
              " -0.0023915577039588243,\n",
              " 0.016186593333259225,\n",
              " -0.22781647369265556,\n",
              " 0.05863626766949892,\n",
              " 0.0023188284831121564,\n",
              " 0.05835096724331379,\n",
              " 0.022494565695524216,\n",
              " -0.00017694284906610847,\n",
              " -0.05023452080786228,\n",
              " -0.027781688142567873,\n",
              " -0.015170966158621013,\n",
              " 0.045988744124770164,\n",
              " 0.03865735649014823,\n",
              " -0.014863897929899395,\n",
              " 0.05207539349794388,\n",
              " -0.05389692448079586,\n",
              " 0.002599978935904801,\n",
              " -0.025946462934371084,\n",
              " 0.025414021452888846,\n",
              " -0.012631861085537821,\n",
              " 0.04960623662918806,\n",
              " 0.032746696611866355,\n",
              " 0.024362302385270596,\n",
              " -0.041093091014772654,\n",
              " 0.12080742977559566,\n",
              " 0.05804291646927595,\n",
              " -0.03230963950045407,\n",
              " -0.014616376254707575,\n",
              " -0.03288973681628704,\n",
              " 0.036602317821234465,\n",
              " -0.045124590396881104,\n",
              " -0.0030797322397120297,\n",
              " 0.07473882241174579,\n",
              " -0.043982372619211674,\n",
              " 0.014314099564217031,\n",
              " -0.021514179185032845,\n",
              " -0.03858722560107708,\n",
              " 0.01361127933341777,\n",
              " -0.016882741707377136,\n",
              " 0.014882401446811855,\n",
              " -0.041467513889074326,\n",
              " 0.03037284640595317,\n",
              " -0.048630541656166315,\n",
              " -0.0036412173649296165,\n",
              " -0.0725028021261096,\n",
              " -0.06775214895606041,\n",
              " 0.06621885485947132,\n",
              " -0.016620048671029508,\n",
              " -0.0015312430332414806,\n",
              " -0.06117668654769659,\n",
              " -0.007626204751431942,\n",
              " -0.048054229468107224,\n",
              " -0.008090602466836572,\n",
              " -0.03858374245464802,\n",
              " 0.046410154551267624,\n",
              " -0.0010761006269603968,\n",
              " 0.04142938833683729,\n",
              " -0.008921859640395269,\n",
              " -0.029853408690541983,\n",
              " 0.02099577832268551,\n",
              " -0.03891030768863857,\n",
              " 0.02747365622781217,\n",
              " 0.05523317400366068,\n",
              " 0.06706410367041826,\n",
              " -0.014807367813773453,\n",
              " 0.08247490972280502,\n",
              " 0.025938228704035282]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Own prompts\n",
        "\n",
        "Besides using preconfigured prompts, we can also easily construct our own prompts and use those in the LLMChain that is generating the documents. This can be useful if we know the domain our queries will be in, as we can condition the prompt to generate text more similar to that."
      ],
      "metadata": {
        "id": "PUyArOIhtkkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Please answer the user's question as a single food item\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "rNKbVEUyrScx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder(llm_chain=llm_chain,\n",
        "                                          base_embeddings=bge_embeddings\n",
        "                                      )"
      ],
      "metadata": {
        "id": "syJC8-vZrSfW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "own_temp_result = embeddings.embed_query(\"What is is McDonalds best selling item?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AqyhUnnrSiZ",
        "outputId": "9532553c-fba0-458b-e203-e79770457cfb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Please answer the user's question as a single food item\\nQuestion: What is is McDonalds best selling item?\\nAnswer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:OpenAI] [338ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" McDonald's best selling item is the Big Mac.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"total_tokens\": 35,\n",
            "      \"completion_tokens\": 10,\n",
            "      \"prompt_tokens\": 25\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "own_temp_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFpTKCu8rSk5",
        "outputId": "e64f0f7e-10e2-419c-eba6-0d475026db28"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.002811376005411148,\n",
              " -0.030611341819167137,\n",
              " 0.030363930389285088,\n",
              " -0.045128967612981796,\n",
              " 0.09638850390911102,\n",
              " -0.00989654939621687,\n",
              " 0.09242162108421326,\n",
              " 0.0007712717051617801,\n",
              " 0.006553604267537594,\n",
              " -0.00699484720826149,\n",
              " -0.026213709264993668,\n",
              " -0.009304863400757313,\n",
              " 0.019638791680336,\n",
              " -0.02891502156853676,\n",
              " 0.03094254620373249,\n",
              " 0.013956543989479542,\n",
              " 0.0731891393661499,\n",
              " -0.08378107845783234,\n",
              " -0.06672555953264236,\n",
              " -0.017184782773256302,\n",
              " 0.058876458555459976,\n",
              " -0.047592777758836746,\n",
              " -0.08618463575839996,\n",
              " 0.017385758459568024,\n",
              " 0.05858829990029335,\n",
              " -0.03111034817993641,\n",
              " -0.011409522034227848,\n",
              " 0.020874688401818275,\n",
              " -0.05026360601186752,\n",
              " -0.10547563433647156,\n",
              " -0.02620377205312252,\n",
              " -0.06658826768398285,\n",
              " 0.09434735774993896,\n",
              " -0.03198225796222687,\n",
              " -0.011794834397733212,\n",
              " 0.02288091741502285,\n",
              " 0.0015589101240038872,\n",
              " -0.04848414659500122,\n",
              " -0.002484525553882122,\n",
              " -0.014121872372925282,\n",
              " 0.12060810625553131,\n",
              " 0.009897193871438503,\n",
              " -0.0020451017189770937,\n",
              " 0.00775568513199687,\n",
              " 0.06158749759197235,\n",
              " 0.0265923123806715,\n",
              " 0.03288228064775467,\n",
              " -0.026106849312782288,\n",
              " 0.09229495376348495,\n",
              " 0.017759982496500015,\n",
              " -0.013945313170552254,\n",
              " -0.01068089809268713,\n",
              " -0.05141704902052879,\n",
              " -0.0035508382134139538,\n",
              " 0.024384330958127975,\n",
              " 0.09127921611070633,\n",
              " 0.007417968008667231,\n",
              " -0.0661245733499527,\n",
              " 0.030484061688184738,\n",
              " 0.014436964876949787,\n",
              " 0.03327514976263046,\n",
              " 0.04395252838730812,\n",
              " -0.09976906329393387,\n",
              " 0.03523660823702812,\n",
              " 0.006989629939198494,\n",
              " -0.023257536813616753,\n",
              " -0.004600428510457277,\n",
              " 0.022139601409435272,\n",
              " -0.10222821682691574,\n",
              " -0.003226690227165818,\n",
              " 0.0842132493853569,\n",
              " -0.03564779832959175,\n",
              " 0.058080825954675674,\n",
              " 0.08409654349088669,\n",
              " 0.007249790709465742,\n",
              " -0.04251695051789284,\n",
              " 0.02702418342232704,\n",
              " 0.007017773576080799,\n",
              " -0.04032774642109871,\n",
              " 0.03740992397069931,\n",
              " 0.0431501604616642,\n",
              " -0.017064077779650688,\n",
              " -0.021910637617111206,\n",
              " -0.04114601016044617,\n",
              " -0.09028688073158264,\n",
              " 0.01729370839893818,\n",
              " -0.06424856930971146,\n",
              " 0.005065350793302059,\n",
              " 0.09647766500711441,\n",
              " -0.040278252214193344,\n",
              " 0.008742695674300194,\n",
              " -0.02585652843117714,\n",
              " -0.008415956981480122,\n",
              " -0.05024511739611626,\n",
              " -0.0391794890165329,\n",
              " 0.004889153875410557,\n",
              " -0.026886969804763794,\n",
              " 0.004794219043105841,\n",
              " 0.035653166472911835,\n",
              " 0.30924952030181885,\n",
              " -0.005203567910939455,\n",
              " 0.047654684633016586,\n",
              " 0.033638034015893936,\n",
              " -0.08168628811836243,\n",
              " 0.011889103800058365,\n",
              " 0.024779843166470528,\n",
              " 0.08017518371343613,\n",
              " 0.05531004071235657,\n",
              " 0.02079223468899727,\n",
              " 0.0044449311681091785,\n",
              " -0.0030174555722624063,\n",
              " 0.051567442715168,\n",
              " 0.03390592709183693,\n",
              " 0.007444900460541248,\n",
              " -0.021790990605950356,\n",
              " -0.044781044125556946,\n",
              " 0.057220250368118286,\n",
              " 0.003017568960785866,\n",
              " -0.02387785166501999,\n",
              " -0.040941767394542694,\n",
              " 0.016441326588392258,\n",
              " 0.10109562426805496,\n",
              " 0.02211960032582283,\n",
              " 0.025586700066924095,\n",
              " -0.10220139473676682,\n",
              " -0.04283004254102707,\n",
              " 0.014382454566657543,\n",
              " 0.09815886616706848,\n",
              " 0.014301515184342861,\n",
              " 0.00048486789455637336,\n",
              " -0.019955618306994438,\n",
              " -0.06160292774438858,\n",
              " -0.005080427974462509,\n",
              " -0.02338341437280178,\n",
              " 0.048542581498622894,\n",
              " -0.012966128066182137,\n",
              " -0.009606386534869671,\n",
              " 0.043636076152324677,\n",
              " 0.04007091000676155,\n",
              " -0.016217635944485664,\n",
              " -0.019185584038496017,\n",
              " -0.009011334739625454,\n",
              " -0.003240634221583605,\n",
              " -0.06853323429822922,\n",
              " 0.02903958037495613,\n",
              " 0.025235429406166077,\n",
              " -0.0017395796021446586,\n",
              " -0.003266869345679879,\n",
              " -0.025364121422171593,\n",
              " 0.021042153239250183,\n",
              " 0.009748770855367184,\n",
              " 0.04117035120725632,\n",
              " 0.02597789652645588,\n",
              " -0.008179382421076298,\n",
              " 0.009506182745099068,\n",
              " 0.007744180038571358,\n",
              " 0.0459272563457489,\n",
              " 0.02470185048878193,\n",
              " 0.005567207001149654,\n",
              " -0.04209452122449875,\n",
              " -0.04232741892337799,\n",
              " 0.02226744219660759,\n",
              " 0.015090175904333591,\n",
              " -0.052388012409210205,\n",
              " 0.017980560660362244,\n",
              " -0.13413137197494507,\n",
              " 0.009824973531067371,\n",
              " -0.015525809489190578,\n",
              " -0.05582653731107712,\n",
              " -0.012042194604873657,\n",
              " -0.02025233954191208,\n",
              " 0.027194878086447716,\n",
              " -0.08276383578777313,\n",
              " 0.04492834955453873,\n",
              " 0.07976460456848145,\n",
              " -0.008683067746460438,\n",
              " -0.0716901645064354,\n",
              " 0.009266311302781105,\n",
              " -0.058283135294914246,\n",
              " -0.03056636080145836,\n",
              " 0.022520380094647408,\n",
              " -0.017160730436444283,\n",
              " -0.058937422931194305,\n",
              " -0.027151914313435555,\n",
              " 0.057181768119335175,\n",
              " -0.03342288359999657,\n",
              " 0.04044732823967934,\n",
              " 0.015304968692362309,\n",
              " 0.02615976892411709,\n",
              " 0.04938754439353943,\n",
              " 0.09751682728528976,\n",
              " 0.12182573974132538,\n",
              " -0.002269140211865306,\n",
              " -0.015476030297577381,\n",
              " -0.027055582031607628,\n",
              " -0.041416727006435394,\n",
              " -0.05458462983369827,\n",
              " 0.05150789022445679,\n",
              " 0.10358116775751114,\n",
              " 0.030915861949324608,\n",
              " -0.04732199385762215,\n",
              " -0.02518761157989502,\n",
              " -0.11790674179792404,\n",
              " -0.05113103985786438,\n",
              " 0.03444191813468933,\n",
              " 0.009712356142699718,\n",
              " -0.05041898041963577,\n",
              " 0.022087393328547478,\n",
              " -0.028226424008607864,\n",
              " -0.010891159065067768,\n",
              " 0.024442046880722046,\n",
              " -0.006608836352825165,\n",
              " 0.03279343247413635,\n",
              " 0.03609025850892067,\n",
              " -0.030053885653614998,\n",
              " -0.0602770671248436,\n",
              " 0.032345641404390335,\n",
              " 0.03880893439054489,\n",
              " -0.037794794887304306,\n",
              " 0.008143934421241283,\n",
              " 0.07650221139192581,\n",
              " 0.014956440776586533,\n",
              " -0.047790445387363434,\n",
              " -0.27082398533821106,\n",
              " 0.010874973610043526,\n",
              " -0.009592262096703053,\n",
              " 0.0031257551163434982,\n",
              " 0.03790166601538658,\n",
              " -0.026883535087108612,\n",
              " 0.017180128023028374,\n",
              " -0.034431975334882736,\n",
              " 0.02392825111746788,\n",
              " 0.05678485706448555,\n",
              " 0.012948814779520035,\n",
              " -0.03792430832982063,\n",
              " -0.015712065622210503,\n",
              " 0.028562534600496292,\n",
              " -0.04518405348062515,\n",
              " 0.0032844827510416508,\n",
              " -0.011094499379396439,\n",
              " 0.005417646374553442,\n",
              " 0.025105886161327362,\n",
              " 0.004113504663109779,\n",
              " 0.024766534566879272,\n",
              " 0.03141161799430847,\n",
              " -0.020996419712901115,\n",
              " 0.04552873224020004,\n",
              " -0.024444738402962685,\n",
              " 0.027940301224589348,\n",
              " 0.15179911255836487,\n",
              " 0.06406436860561371,\n",
              " 0.01567750982940197,\n",
              " 0.005048764403909445,\n",
              " -0.010365464724600315,\n",
              " 0.06783530116081238,\n",
              " -0.03810180723667145,\n",
              " -0.002533772261813283,\n",
              " 0.035229574888944626,\n",
              " 0.059686947613954544,\n",
              " 0.02455417811870575,\n",
              " -0.009650276973843575,\n",
              " -0.05036911740899086,\n",
              " 0.03036510944366455,\n",
              " -0.028806263580918312,\n",
              " 0.013271314091980457,\n",
              " 0.005014385096728802,\n",
              " -0.10364561527967453,\n",
              " -0.016874181106686592,\n",
              " -0.037866465747356415,\n",
              " 0.0663466677069664,\n",
              " 0.036066070199012756,\n",
              " -0.052461400628089905,\n",
              " 0.047313153743743896,\n",
              " -0.0030513866804540157,\n",
              " -0.0003792869974859059,\n",
              " 0.06452328711748123,\n",
              " -0.034068237990140915,\n",
              " -0.009623486548662186,\n",
              " -0.01766006276011467,\n",
              " 0.011630654335021973,\n",
              " -0.09280382096767426,\n",
              " -0.0028915598522871733,\n",
              " -0.016250109300017357,\n",
              " -0.011475957930088043,\n",
              " -0.007240236271172762,\n",
              " -0.0614059753715992,\n",
              " 0.04558807983994484,\n",
              " 0.0304886344820261,\n",
              " -0.03698227182030678,\n",
              " 0.021766144782304764,\n",
              " 0.07910101860761642,\n",
              " -0.0828268975019455,\n",
              " 0.0009963869815692306,\n",
              " -0.04224107787013054,\n",
              " -0.04485038295388222,\n",
              " 0.03674139827489853,\n",
              " -0.013593542389571667,\n",
              " 0.05735987797379494,\n",
              " 0.00010044112423202023,\n",
              " 0.0020885546691715717,\n",
              " -0.04741773009300232,\n",
              " -0.03985748812556267,\n",
              " 0.016225390136241913,\n",
              " 0.0368226133286953,\n",
              " 0.05276579037308693,\n",
              " -0.038084425032138824,\n",
              " 0.033791638910770416,\n",
              " 0.07497803121805191,\n",
              " -0.03766941651701927,\n",
              " -0.010870515368878841,\n",
              " 0.03237224742770195,\n",
              " -0.03887666389346123,\n",
              " -0.021743563935160637,\n",
              " 0.05113937705755234,\n",
              " -0.03212187439203262,\n",
              " -0.04973546415567398,\n",
              " -0.07152938842773438,\n",
              " -0.025148360058665276,\n",
              " 0.038276541978120804,\n",
              " -0.256305456161499,\n",
              " 0.038479793816804886,\n",
              " -0.05681805685162544,\n",
              " 0.032241228967905045,\n",
              " -0.02053283527493477,\n",
              " -0.00236901524476707,\n",
              " -0.07295295596122742,\n",
              " 0.05795299634337425,\n",
              " -0.002975010545924306,\n",
              " 0.05663125962018967,\n",
              " 0.01042603887617588,\n",
              " 0.003974733408540487,\n",
              " 0.055979300290346146,\n",
              " -0.020822973921895027,\n",
              " 0.006218464579433203,\n",
              " -0.05184055119752884,\n",
              " -0.005527709145098925,\n",
              " -0.03184985741972923,\n",
              " 0.07289406657218933,\n",
              " 0.02840995043516159,\n",
              " 0.012345950119197369,\n",
              " -0.007549668196588755,\n",
              " 0.11362051963806152,\n",
              " 0.022026685997843742,\n",
              " -0.0331096351146698,\n",
              " -0.006273746024817228,\n",
              " -0.05587166175246239,\n",
              " 0.03019740618765354,\n",
              " -0.027123598381876945,\n",
              " -0.050146281719207764,\n",
              " 0.12136933952569962,\n",
              " -0.04573837295174599,\n",
              " 0.020129572600126266,\n",
              " -0.03591743856668472,\n",
              " -0.03228536993265152,\n",
              " 0.03253612667322159,\n",
              " -0.030021900311112404,\n",
              " -0.0260370671749115,\n",
              " -0.025561679154634476,\n",
              " 0.020816849544644356,\n",
              " -0.05290323123335838,\n",
              " -0.0033480417914688587,\n",
              " -0.07958174496889114,\n",
              " -0.037521522492170334,\n",
              " 0.09825417399406433,\n",
              " -0.02150760032236576,\n",
              " 0.0038321963511407375,\n",
              " -0.04834009334445,\n",
              " 0.02279702201485634,\n",
              " -0.05971696227788925,\n",
              " -0.04227354750037193,\n",
              " -0.03749179095029831,\n",
              " 0.035726144909858704,\n",
              " 0.0023015073966234922,\n",
              " 0.02076573669910431,\n",
              " -0.03528377786278725,\n",
              " -0.04731716588139534,\n",
              " 0.04432009905576706,\n",
              " -0.04251553863286972,\n",
              " 0.004255691543221474,\n",
              " 0.02363644354045391,\n",
              " 0.04666295647621155,\n",
              " -0.058185141533613205,\n",
              " 0.059502243995666504,\n",
              " 0.015603810548782349]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using HyDE - Hypothetical Document Embeddings\n",
        "\n",
        "We can use it as we would any other embedding class. Here is using it to find similar passages in the state of the union example."
      ],
      "metadata": {
        "id": "8d1-1pbHuF7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "0oF4BAsduB-F"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [\n",
        "    TextLoader('/content/blog_posts/blog.langchain.dev_announcing-langsmith_.txt'),\n",
        "    TextLoader('/content/blog_posts/blog.langchain.dev_benchmarking-question-answering-over-csv-data_.txt'),\n",
        "    TextLoader('/content/blog_posts/blog.langchain.dev_chat-loaders-finetune-a-chatmodel-in-your-voice_.txt'),\n",
        "]"
      ],
      "metadata": {
        "id": "eDN3TgYguCBO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "for l in loaders:\n",
        "    documents.extend(l.load())"
      ],
      "metadata": {
        "id": "X29f55sarSrO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "95WussRHuhRM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(documents) #split_text"
      ],
      "metadata": {
        "id": "zTHVXoJVuhZk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRisAKOHuhc0",
        "outputId": "e0e38ce8-0ccf-4a88-fb2b-ccaf0ac9966e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Please answer the user's question as related to Large Language Models\n",
        "                        Question: {question}\n",
        "                        Answer:\"\"\""
      ],
      "metadata": {
        "id": "g9ufbO18uhh3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)"
      ],
      "metadata": {
        "id": "nvvreimQuyhv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "4ZZGuAXFuyk4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder(\n",
        "    llm_chain=llm_chain,\n",
        "    base_embeddings=bge_embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "EWaZoISBuynn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "lTd0opJ8u5id"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are chat loaders?\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdoZBULru5lF",
        "outputId": "1b436d3a-231e-4af0-a257-6522e757b831"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Please answer the user's question as related to Large Language Models\\n                        Question: What are chat loaders?\\n                        Answer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:OpenAI] [1.90s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" Chat loaders are tools that are used to facilitate dialog between humans and computers through a chat interface. They can range from simple rule-based systems to more advanced artificial intelligence models, such as large language models. These models use natural language processing techniques to understand and generate human-like responses, making them ideal for use in chat loaders. They can be trained on large datasets of human conversations, allowing them to generate highly relevant and context-aware responses. As large language models continue to advance, chat loaders are becoming increasingly popular for a variety of applications, including customer service, virtual assistants, and chatbots.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"total_tokens\": 141,\n",
            "      \"completion_tokens\": 117,\n",
            "      \"prompt_tokens\": 24\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haam42dAu5nh",
        "outputId": "30d1e2b4-f68a-4619-a9a1-1ee89d0a61f5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://blog.langchain.dev/chat-loaders-finetune-a-chatmodel-in-your-voice/\n",
            "Title: Chat Loaders: Fine-tune a ChatModel in your Voice\n",
            "\n",
            "Summary\n",
            "\n",
            "We are adding a new integration type, ChatLoaders, to make it easier to fine-tune models on your own unique writing style. These utilities help convert data from popular messaging platforms to chat messages compatible with fine-tuning formats like that supported by OpenAI.\n",
            "\n",
            "Thank you to Greg Kamradt for Misbah Syed for their thought leadership on this.\n",
            "\n",
            "Important Links:\n",
            "\n",
            "Context\n",
            "\n",
            "On Tuesday, OpenAI announced improved fine-tuning support, extending the service to larger chat models like GPT-3.5-turbo. This enables anyone to customize these larger, more capable models for their own use cases. They also teased support for fine-tuning GPT-4 later this year.\n",
            "\n",
            "While fine-tuning is typically not advised for teaching an LLM substantially new knowledge or for factual recall; it is good for style transfer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XsYocs3uhkR",
        "outputId": "f6aef706-bec6-47ec-dbaa-5d1ee322df8d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These utilities take data exported from popular messaging platforms and convert them to LangChain message objects, which you can then easily convert platform-agnostic message formats, such as OpenAI, Llama 2, and others. This training data can be used directly for fine-tuning a model.\n",
            "\n",
            "We've added loaders for the following popular messaging platforms so far:\n",
            "\n",
            "Facebook Messenger\n",
            "\n",
            "Slack\n",
            "\n",
            "Telegram\n",
            "\n",
            "WhatsApp\n",
            "\n",
            "We have also added a recipe on how to do so for Discord and Twitter (using Apify) and plan to integrate additional chat loaders in the near future. If you have a favorite messaging platform you'd like to support, we'd love to help you land a PR!\n",
            "\n",
            "To get you started, we've added an end-to-end example notebook to the LangChain documentation showing how to fine-tune gpt-3.5-turbo (the model behind ChatGPT) on an example set of Facebook messages.\n",
            "\n",
            "❗ Please ensure all participants of your conversations support the decision to train a model on the chat data before proceeding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6j7KRW4vJet",
        "outputId": "7e54dcb6-69f3-4f30-c1ca-42ce0e56513b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're excited to see all the creative applications fine-tuning unlocks. We have implemented a few ChatLoaders already, but we need your help to make it easier to create your own personalized model. Help us create more ChatLoaders!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[3].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4NGbIrnvNyW",
        "outputId": "b9f4486a-54c6-4477-e299-33fb4b3c46e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why is this better than direct instructions? Style and tone can be hard to describe! Most of us don't write like ChatGPT, and it can sometimes be frustratingly difficult to get the LLM to consistently respond in a particular voice (especially over longer conversations).\n",
            "\n",
            "Why is this better than few-shot examples? It can be challenging to capture your voice in only a few concise snippets! Fine-tuning lets you provide a larger number of examples the model can learn from without having to see them every time you want to query the model.\n",
            "\n",
            "ChatLoaders\n",
            "\n",
            "At LangChain, we want to make it as easy as possible for you to take advantage of this improved fine-tuning support. To make it simple to adapt a model to your voice, we're adding a new integration type: ChatLoaders .\n"
          ]
        }
      ]
    }
  ]
}